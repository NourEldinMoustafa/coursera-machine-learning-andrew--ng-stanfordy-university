# coursera-machine-learning-andrew-ng-stanfordy-university
 **ranked as one of the top machine learning courses, a staple course in machine learning,**
 ## Module 1 – Introduction to Machine Learning
 ## Module 2 – Supervised Learning and Linear Regression
 ## Module 3 – Classification and Logistic Regression
 ## Module 4 – Neural Networks: Representation
 ## Module 5 – Neural Networks: Learning
 ## Module 6 – Best practices for applying machine learning in practice
 ## Module 7 – Support Vector Machines
 ## Module 8 – Unsupervised Learning
 ## Module 9 – Anomaly Detection
    
    
## Week 1
* Introduction to ML
* Linear Regression with One Variable
* Linear Algebra Review
* Supervised Learning
* Model Representation
* VideoCost Function - Intuition
* Gradient Descent For Linear Regression

## Week 2		
* Linear Regression		
* Multivariate Linear Regression
* Multiple Features
* Gradient Descent For Multiple Variables
* Gradient Descent in Practice I - Feature Scaling
* Gradient Descent in Practice - Learning Rate
* Features and Polynomial Regression
* Computing Parameters Analytically
* Normal Equation Noninvertibility
* Programming Assignments
* Linear Regression with Multiple Variables

## Week 3	
* Classification and Representation
* Hypothesis Representation
* Decision Boundary
* Logistic Regression Model
* Simplified Cost Function and Gradient Descent
* dvanced Optimization
* Multiclass Classification
* Multiclass Classification: One-vs-all
* Regularization, which helps prevent models from overfitting the training data.
* Solving The Problem of Overfitting
* Cost Function
* Regularized Logistic Regression

## Week 4
* Neural Networks: Representation
 * Non-linear Hypotheses
 * Neurons and the Brain
 * Neural Networks
 * Model Representation I
 * Model Representation II
 * Applications, ReadingExamples and Intuitions I
 * Multiclass Classification

## Week 5			
* Cost Function and Backpropagation
* Backpropagation Algorithm & Intuition
* Backpropagation in Practice
* Implementation Note: Unrolling Parameters
* Gradient Checking
* Random Initialization
* VideoPutting It Together
* Application of Neural Networks
* Autonomous Driving

## Week 6
* Evaluating a Learning Algorithm
* Evaluating a Hypothesis
* Model Selection and Train/Validation/Test Sets
* Bias vs. Variance
* Diagnosing Bias vs. Variance
* Regularization and Bias/Variance
* Regularization and Bias/Variance
* Learning Curves
* Deciding What to do Next Revisited
* Regularized Linear Regression and Bias/Variance
* Machine Learning System Design
* Building a Spam Classifier
* Prioritizing What to Work On
* Error Analysis
* Handling Skewed Data
* Error Metrics for Skewed Classes
* Trading Off Precision and Recall
* Using Large Data Sets

## Week 7	
* Large Margin Classification
* Optimization Objective
* Large Margin Intuition
* Mathematics Behind Large Margin Classification
* Kernels I
* Kernels II
* SVMs in Practice
* Using An SVM

## Week 8
* Clustering
* Unsupervised Learning: Introduction
* K-Means Algorithm
* Optimization Objective
* Random Initialization
* Choosing the Number of Clusters
* Unsupervised Learning
* Dimensionality Reduction
* Motivation I: Data Compression
* Motivation II: Visualization
* Principal Component Analysis Problem Formulation
* Principal Component Analysis Algorithm
* Applying PCA
* Reconstruction from Compressed Representation
* Choosing the Number of Principal Components
* Advice for Applying PCA

## Week 9		
	

## Week 10

## Week 11			

## Week 12

   
  
