# coursera-machine-learning-andrew-ng-stanfordy-university  
## Week 1 :–  Introduction to Machine Learning
* Introduction to ML
* Linear Regression with One Variable
* Linear Algebra Review
* Supervised Learning
* Model Representation
* VideoCost Function - Intuition
* Gradient Descent For Linear Regression
--------------
## Week 2 :–  Supervised Learning and Linear Regression
### Programming Exercise 1: Linear Regression
In this exercise, i implemented linear regression and recognized how it work on real world datasets.		
## week topics:
 * Linear Regression		
 * Multivariate Linear Regression
 * Multiple Features
 * Gradient Descent For Multiple Variables
 * Gradient Descent in Practice I - Feature Scaling
 * Gradient Descent in Practice - Learning Rate
 * Features and Polynomial Regression
 * Computing Parameters Analytically
 * Normal Equation Noninvertibility
 * Programming Assignments
 * Linear Regression with Multiple Variables
--------------
## Week 3 :– Classification and Logistic Regression
###### Programming Exercise 2: Logistic Regression
In this exercise, i implemented logistic regression and applied it to two different datasets.
## week topics:
* Classification and Representation
* Hypothesis Representation
* Decision Boundary
* Logistic Regression Model
* Simplified Cost Function and Gradient Descent
* dvanced Optimization
* Multiclass Classification
* Multiclass Classification: One-vs-all
* Regularization, which helps prevent models from overfitting the training data.
* Solving The Problem of Overfitting
* Cost Function
* Regularized Logistic Regression
--------------
## Week 4 :– Neural Networks: Representation
###### Programming Exercise 3: Multi-class Classification and Neural Networks
In this exercise, i implemented one-vs-all logistic regression and feedforward propagation for neural networks to recognize handwritten digits.
## week topics:
* Neural Networks: Representation
 * Non-linear Hypotheses
 * Neurons and the Brain
 * Neural Networks
 * Model Representation I
 * Model Representation II
 * Applications, ReadingExamples and Intuitions I
 * Multiclass Classification
--------------
## Week 5 :– Neural Networks: Learning	
###### Programming Exercise 4: Neural Network Learning
In this exercise, i implemented the backpropagation algorithm for neural networks and applied it to the task of hand-written digit recognition.
## week topics:
* Cost Function and Backpropagation
* Backpropagation Algorithm & Intuition
* Backpropagation in Practice
* Implementation Note: Unrolling Parameters
* Gradient Checking
* Random Initialization
* VideoPutting It Together
* Application of Neural Networks
* Autonomous Driving
--------------
## Week 6 – Best practices for applying machine learning in practice
###### Programming Exercise 5: Regularized Linear Regression and Bias vs Variance
In this exercise, i implemented regularized linear regression and polynomial regression and used it to study models with different bias-variance properties.
## week topics:
* Evaluating a Learning Algorithm
* Evaluating a Hypothesis
* Model Selection and Train/Validation/Test Sets
* Bias vs. Variance
* Diagnosing Bias vs. Variance
* Regularization and Bias/Variance
* Regularization and Bias/Variance
* Learning Curves
* Deciding What to do Next Revisited
* Regularized Linear Regression and Bias/Variance
* Machine Learning System Design
* Building a Spam Classifier
* Prioritizing What to Work On
* Error Analysis
* Handling Skewed Data
* Error Metrics for Skewed Classes
* Trading Off Precision and Recall
* Using Large Data Sets
--------------
## Week 7 :– Support Vector Machines
###### Programming Exercise 6: Support Vector Machines
In this exercise, you will implement support vector machine (SVM) with Gaussian Kernels and you will be using support vector machines (SVMs) to build a spam classifier.
## week topics:
* Large Margin Classification
* Optimization Objective
* Large Margin Intuition
* Mathematics Behind Large Margin Classification
* Kernels I
* Kernels II
* SVMs in Practice
* Using An SVM
--------------
## Week 8 :– Unsupervised Learning
###### Programming Exercise 7: K-means Clustering and Principal Component Analysis
In this exercise, you will implement the K-means clustering algorithm and apply it to compress an image. In the second part, you will use principal component analysis to find a low-dimensional representation of face images.
## week topics:
* Clustering
* Unsupervised Learning: Introduction
* K-Means Algorithm
* Optimization Objective
* Random Initialization
* Choosing the Number of Clusters
* Unsupervised Learning
* Dimensionality Reduction
* Motivation I: Data Compression
* Motivation II: Visualization
* Principal Component Analysis Problem Formulation
* Principal Component Analysis Algorithm
* Applying PCA
* Reconstruction from Compressed Representation
* Choosing the Number of Principal Components
* Advice for Applying PCA
--------------
## Week 9 :– Anomaly Detection
###### Programming Exercise 8: Anomaly Detection and Recommender Systems
In this exercise, you will implement the anomaly detection algorithm and apply it to detect failing servers on a network. In the second part, you will use collaborative filtering to build a recommender system for movies.
## week topics:
	
--------------
## Week 10
###### Programming Exercise
## week topics:
--------------
## Week 11
###### Programming Exercise
## week topics:
--------------
## Week 12
###### Programming Exercise
## week topics:

   
  
